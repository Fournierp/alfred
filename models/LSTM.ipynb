{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Stock Market Data\n",
    "\n",
    "In this kernel, we will design and train the model we will use in our web app. We will develop a Long Short-Term Memory (LSTM) Neural Network and harness its capability to solve problems in time series. This model will take as input Closing Stock Prices of previous days and predict the next days Stock Prices.\n",
    "\n",
    "Most resources online showed how to train a LSTM model on a single company's historical stock market dataset. Yet I want a model I can use to predict prices for various companies on the Alfred web-app. So I will aggregate a lot of data on publicly traded companies and train a model that can capture live stock market patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib inline\n",
    "\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColumnDataSource, RangeTool, HoverTool\n",
    "from bokeh.plotting import figure, output_notebook, show, save\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same list of companies that can be studied on Alfred\n",
    "companies = pd.read_html('https://en.wikipedia.org/wiki/List_of_S'\n",
    "                         '%26P_500_companies')[0]\n",
    "# For the sake of the Proof Of Concept, we will use fewer companies than that\n",
    "companies = companies[['Symbol']][companies['GICS Sector'] == 'Information Technology'].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAPL'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a random company for evaluation\n",
    "index = int(np.random.random()*len(companies))\n",
    "eval_company = companies[index]\n",
    "companies = np.delete(companies, index)\n",
    "eval_company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first challenge posed to us is to format the data. The LSTM needs a window of historical data points and a window of target points. This function splits the data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape the data into strips of historical prices for the LSTM\n",
    "input_len = 30\n",
    "output_len = 1\n",
    "\n",
    "def split_data_prices_in_windows(df):\n",
    "    \"\"\"\n",
    "    Create series of \"input_len\" Closing prices (X) and its coresponding \"output_len\" price (Y).  \n",
    "    \"\"\"\n",
    "    LSTM_inputs = []\n",
    "    LSTM_outputs = []\n",
    "    for i in range(input_len, len(df)):\n",
    "        # Process the model's input sequence\n",
    "        historical_prices = df[i-input_len : i].copy()\n",
    "        LSTM_inputs.append(np.array(historical_prices))\n",
    "        \n",
    "        # Process the model's expected output sequence\n",
    "        target_price = df[i].copy()        \n",
    "        LSTM_outputs.append(np.array(target_price))\n",
    "        \n",
    "    LSTM_inputs = np.array(LSTM_inputs)\n",
    "    LSTM_outputs = np.array(LSTM_outputs)\n",
    "    \n",
    "    return LSTM_inputs, LSTM_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download all this data and store it in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# We will manually create the arrays with the first company before looping for the rest\n",
    "cmp = yf.download(companies[0])\n",
    "# Get the closing price into a train and test array\n",
    "train_set = cmp.iloc[:int(cmp.shape[0]*.80), 3:4].values\n",
    "test_set = cmp.iloc[int(cmp.shape[0]*.80):, 3:4].values\n",
    "# Get the closing price into format acceptable for the LSTM\n",
    "x_train, y_train = split_data_prices_in_windows(train_set)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1]))\n",
    "x_test, y_test = split_data_prices_in_windows(test_set)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1]))\n",
    "\n",
    "for company in companies[1:]:\n",
    "    cmp = yf.download(company)\n",
    "    # Get the closing price into a train and test array\n",
    "    train_set_tmp = cmp.iloc[:int(cmp.shape[0]*.80), 3:4].values\n",
    "    test_set_tmp = cmp.iloc[int(cmp.shape[0]*.80):, 3:4].values\n",
    "    # Get the closing price into format acceptable for the LSTM\n",
    "    x_train_tmp, y_train_tmp = split_data_prices_in_windows(train_set)\n",
    "    x_train_tmp = np.reshape(x_train_tmp, (x_train_tmp.shape[0], x_train_tmp.shape[1]))\n",
    "    x_test_tmp, y_test_tmp = split_data_prices_in_windows(test_set)\n",
    "    x_test_tmp = np.reshape(x_test_tmp, (x_test_tmp.shape[0], x_test_tmp.shape[1]))\n",
    "    # Gather the data points into a single array\n",
    "    x_train = np.concatenate((x_train, x_train_tmp))\n",
    "    x_test = np.concatenate((x_test, x_test_tmp))\n",
    "    y_train = np.concatenate((y_train, y_train_tmp))\n",
    "    y_test = np.concatenate((y_test, y_test_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have numerous company's historical stock market data, let us process it to facilitate the learning of the LSTM. Given the different scales of the companies, their stocks have different values. Let's scale the data according to the MinMaxScaler: normalize the data between (0, 1) based on the the overall maximum and minimum prices of all companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "total_max = x_train.max()\n",
    "total_min = x_train.min()\n",
    "\n",
    "x_train = (x_train - total_min) / (total_max - total_min)\n",
    "x_test = (x_test - total_min) / (total_max - total_min)\n",
    "y_train = (y_train - total_min) / (total_max - total_min)\n",
    "y_test = (y_test - total_min) / (total_max - total_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = {\n",
    "    'total_max' : total_max,\n",
    "    'total_min' : total_min,\n",
    "    'output_len' : output_len,\n",
    "    'input_len' : input_len,\n",
    "}\n",
    "\n",
    "with open('checkpoints/data.txt', 'w') as outfile:\n",
    "    json.dump(model_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the train data to avoid bias due to the ordering of data.\n",
    "x_train, y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data for the LSTM model\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRScheduler(Callback):\n",
    "    '''Cosine annealing learning rate scheduler with periodic restarts.\n",
    "    # Usage\n",
    "        ```python\n",
    "            schedule = SGDRScheduler(min_lr=1e-5,\n",
    "                                     max_lr=1e-2,\n",
    "                                     steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                                     lr_decay=0.9,\n",
    "                                     cycle_length=5,\n",
    "                                     mult_factor=1.5)\n",
    "            model.fit(X_train, Y_train, epochs=100, callbacks=[schedule])\n",
    "        ```\n",
    "        \n",
    "    # Arguments\n",
    "        min_lr: The lower bound of the learning rate range for the experiment.\n",
    "        max_lr: The upper bound of the learning rate range for the experiment.\n",
    "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`. \n",
    "        lr_decay: Reduce the max_lr after the completion of each cycle.\n",
    "                  Ex. To reduce the max_lr by 20% after each cycle, set this value to 0.8.\n",
    "        cycle_length: Initial number of epochs in a cycle.\n",
    "        mult_factor: Scale epochs_to_restart after each full cycle completion.\n",
    "        \n",
    "    # References\n",
    "        Blog post: jeremyjordan.me/nn-learning-rate\n",
    "        Original paper: http://arxiv.org/abs/1608.03983\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 min_lr,\n",
    "                 max_lr,\n",
    "                 steps_per_epoch,\n",
    "                 lr_decay=1,\n",
    "                 cycle_length=10,\n",
    "                 mult_factor=2):\n",
    "\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.lr_decay = lr_decay\n",
    "\n",
    "        self.batch_since_restart = 0\n",
    "        self.next_restart = cycle_length\n",
    "\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "        self.cycle_length = cycle_length\n",
    "        self.mult_factor = mult_factor\n",
    "\n",
    "        self.history = {}\n",
    "\n",
    "    def clr(self):\n",
    "        '''Calculate the learning rate.'''\n",
    "        fraction_to_restart = self.batch_since_restart / (self.steps_per_epoch * self.cycle_length)\n",
    "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(fraction_to_restart * np.pi))\n",
    "        return lr\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
    "        logs = logs or {}\n",
    "        K.set_value(self.model.optimizer.lr, self.max_lr)\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        '''Record previous batch statistics and update the learning rate.'''\n",
    "        logs = logs or {}\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "\n",
    "        self.batch_since_restart += 1\n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        '''Check for end of current cycle, apply restarts when necessary.'''\n",
    "        if epoch + 1 == self.next_restart:\n",
    "            self.batch_since_restart = 0\n",
    "            self.cycle_length = np.ceil(self.cycle_length * self.mult_factor)\n",
    "            self.next_restart += self.cycle_length\n",
    "            self.max_lr *= self.lr_decay\n",
    "            self.best_weights = self.model.get_weights()\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        '''Set weights to the values from the end of the most recent cycle for best performance.'''\n",
    "        self.model.set_weights(self.best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def __init__(self):\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def on_batch_end(self, epoch, logs={}):\n",
    "        self.loss.append(logs.get('loss'))\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.val_loss.append(logs.get('val_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(input_shape, output_shape, neurons, dropout):\n",
    "    x = Input(shape=input_shape)\n",
    "    hidden = LSTM(neurons, return_sequences=True)(x)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    hidden = LSTM(neurons, return_sequences=True)(x)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    hidden = LSTM(neurons, return_sequences=True)(x)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    hidden = LSTM(neurons, return_sequences=False)(hidden)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    y = Dense(output_shape, activation='linear')(hidden)\n",
    "    return Model(inputs=x, outputs=y)\n",
    "\n",
    "model = LSTM_model((input_len, 1), output_len, 50, 0.2)\n",
    "\n",
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "\n",
    "model.compile(optimizer=optimizer, metrics=['mse'], loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2122/2122 [==============================] - 9s 4ms/step - loss: 1.8978 - mse: 1.8978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8977795839309692, 1.8977795839309692]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Create the Learning Rate Scheduler Callback\n",
    "schedule = SGDRScheduler(min_lr=1e-5,\n",
    "                         max_lr=1e-4,\n",
    "                         steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                         lr_decay=0.9,\n",
    "                         cycle_length= 3,\n",
    "                         mult_factor=1.5)\n",
    "\n",
    "# Callback function to graph losses\n",
    "lh = LossHistory()\n",
    "\n",
    "# Callback function to stopp when the validation loss stagnates\n",
    "es = EarlyStopping(patience=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8685/8685 [==============================] - 122s 14ms/step - loss: 0.0025 - mse: 0.0025 - val_loss: 0.0161 - val_mse: 0.0161\n",
      "Epoch 2/100\n",
      "8685/8685 [==============================] - 118s 14ms/step - loss: 8.7858e-04 - mse: 8.7858e-04 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 3/100\n",
      "8685/8685 [==============================] - 136s 16ms/step - loss: 6.7504e-04 - mse: 6.7504e-04 - val_loss: 0.0142 - val_mse: 0.0142\n",
      "Epoch 4/100\n",
      "8685/8685 [==============================] - 137s 16ms/step - loss: 5.7849e-04 - mse: 5.7849e-04 - val_loss: 0.0077 - val_mse: 0.0077\n",
      "Epoch 5/100\n",
      "8685/8685 [==============================] - 135s 16ms/step - loss: 5.2167e-04 - mse: 5.2167e-04 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 6/100\n",
      "8685/8685 [==============================] - 140s 16ms/step - loss: 4.9217e-04 - mse: 4.9217e-04 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 7/100\n",
      "8685/8685 [==============================] - 140s 16ms/step - loss: 4.7924e-04 - mse: 4.7924e-04 - val_loss: 0.0068 - val_mse: 0.0068\n",
      "Epoch 8/100\n",
      "8685/8685 [==============================] - 138s 16ms/step - loss: 4.6191e-04 - mse: 4.6191e-04 - val_loss: 0.0082 - val_mse: 0.0082\n",
      "Epoch 9/100\n",
      "8685/8685 [==============================] - 131s 15ms/step - loss: 4.5241e-04 - mse: 4.5241e-04 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 10/100\n",
      "8685/8685 [==============================] - 129s 15ms/step - loss: 4.4900e-04 - mse: 4.4900e-04 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 11/100\n",
      "8685/8685 [==============================] - 135s 16ms/step - loss: 4.4302e-04 - mse: 4.4302e-04 - val_loss: 0.0060 - val_mse: 0.0060\n",
      "Epoch 12/100\n",
      "8685/8685 [==============================] - 130s 15ms/step - loss: 4.3787e-04 - mse: 4.3787e-04 - val_loss: 0.0059 - val_mse: 0.0059\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_data = (x_test, y_test),\n",
    "          epochs = epoch_size, batch_size = batch_size, callbacks=[lh, schedule, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"checkpoints/lstm_next_price_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"checkpoints/lstm_next_price.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2122/2122 [==============================] - 10s 5ms/step - loss: 0.0082 - mse: 0.0082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.008218631148338318, 0.008218631148338318]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(16,6))\n",
    "ax1.plot(lh.loss)\n",
    "ax1.set_title('Train Loss')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_xlabel('Batch')\n",
    "ax2.plot(lh.val_loss)\n",
    "ax2.set_title('Validation Loss')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on unseen stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.100266</td>\n",
       "      <td>469033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.095035</td>\n",
       "      <td>175884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.088059</td>\n",
       "      <td>105728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17</th>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.090239</td>\n",
       "      <td>86441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18</th>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.092855</td>\n",
       "      <td>73449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>120.500000</td>\n",
       "      <td>121.989998</td>\n",
       "      <td>116.050003</td>\n",
       "      <td>116.320000</td>\n",
       "      <td>116.320000</td>\n",
       "      <td>154515300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10</th>\n",
       "      <td>115.550003</td>\n",
       "      <td>117.589996</td>\n",
       "      <td>114.129997</td>\n",
       "      <td>115.970001</td>\n",
       "      <td>115.970001</td>\n",
       "      <td>138023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-11</th>\n",
       "      <td>117.190002</td>\n",
       "      <td>119.629997</td>\n",
       "      <td>116.440002</td>\n",
       "      <td>119.489998</td>\n",
       "      <td>119.489998</td>\n",
       "      <td>112295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-12</th>\n",
       "      <td>119.620003</td>\n",
       "      <td>120.529999</td>\n",
       "      <td>118.570000</td>\n",
       "      <td>119.209999</td>\n",
       "      <td>119.209999</td>\n",
       "      <td>103162300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-13</th>\n",
       "      <td>119.440002</td>\n",
       "      <td>119.669998</td>\n",
       "      <td>117.870003</td>\n",
       "      <td>119.260002</td>\n",
       "      <td>119.260002</td>\n",
       "      <td>81581900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10067 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "1980-12-12    0.128348    0.128906    0.128348    0.128348    0.100266   \n",
       "1980-12-15    0.122210    0.122210    0.121652    0.121652    0.095035   \n",
       "1980-12-16    0.113281    0.113281    0.112723    0.112723    0.088059   \n",
       "1980-12-17    0.115513    0.116071    0.115513    0.115513    0.090239   \n",
       "1980-12-18    0.118862    0.119420    0.118862    0.118862    0.092855   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2020-11-09  120.500000  121.989998  116.050003  116.320000  116.320000   \n",
       "2020-11-10  115.550003  117.589996  114.129997  115.970001  115.970001   \n",
       "2020-11-11  117.190002  119.629997  116.440002  119.489998  119.489998   \n",
       "2020-11-12  119.620003  120.529999  118.570000  119.209999  119.209999   \n",
       "2020-11-13  119.440002  119.669998  117.870003  119.260002  119.260002   \n",
       "\n",
       "               Volume  \n",
       "1980-12-12  469033600  \n",
       "1980-12-15  175884800  \n",
       "1980-12-16  105728000  \n",
       "1980-12-17   86441600  \n",
       "1980-12-18   73449600  \n",
       "...               ...  \n",
       "2020-11-09  154515300  \n",
       "2020-11-10  138023400  \n",
       "2020-11-11  112295000  \n",
       "2020-11-12  103162300  \n",
       "2020-11-13   81581900  \n",
       "\n",
       "[10067 rows x 6 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = yf.download(eval_company)\n",
    "df.index.name = None\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = df.iloc[:, 3:4].values\n",
    "\n",
    "x_eval, y_eval = split_data_prices_in_windows(eval_set)\n",
    "x_eval = np.reshape(x_eval, (x_eval.shape[0], x_eval.shape[1]))\n",
    "\n",
    "x_eval = (x_eval - total_min) / (total_max - total_min)\n",
    "y_eval = (y_eval - total_min) / (total_max - total_min)\n",
    "x_eval = np.reshape(x_eval, (x_eval.shape[0], x_eval.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = model.predict(x_eval)\n",
    "# Transform the predicted data back to stock prices\n",
    "predicted_stock_price = predicted_stock_price * (total_max - total_min) + total_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fournierp/.local/share/virtualenvs/alfred-Mlefol6Z/lib/python3.8/site-packages/bokeh/io/saving.py:126: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
      "  warn(\"save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\")\n",
      "/home/fournierp/.local/share/virtualenvs/alfred-Mlefol6Z/lib/python3.8/site-packages/bokeh/io/saving.py:139: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
      "  warn(\"save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/fournierp/Documents/alfred/models/plots/lstm_next_price.html'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(eval_set, index=df.iloc[:, 3:4].index, columns=[\"Close\"])\n",
    "df2 = pd.DataFrame(predicted_stock_price, index= df.iloc[input_len:, 3:4].index, columns=[\"Close\"])\n",
    "df1[\"Date\"] = pd.to_datetime(df1.index)\n",
    "df2[\"Date\"] = pd.to_datetime(df2.index)\n",
    "dates1 = df1['Date']\n",
    "dates2 = df2['Date']\n",
    "source1 = ColumnDataSource(data=dict(date=dates1, close=df1['Close']))\n",
    "source2 = ColumnDataSource(data=dict(date=dates2, close=df2['Close']))\n",
    "\n",
    "p = figure(plot_height=300, plot_width=800, tools=\"xpan\", toolbar_location=None,\n",
    "           x_axis_type=\"datetime\", x_axis_location=\"above\",\n",
    "           background_fill_color=\"#efefef\", x_range=(dates1[dates1.index[-100]], dates1[dates1.index[-1]]))\n",
    "tmp = p.x_range # Store it before adding multiple lines\n",
    "p.line('date', 'close', source=source1, legend_label='Real Stock Price', color='green')\n",
    "p.line('date', 'close', source=source2, legend_label='Predicted Stock Price', color='blue')\n",
    "\n",
    "p.yaxis.axis_label = 'Price'\n",
    "\n",
    "\n",
    "hover_tool = HoverTool(\n",
    "    tooltips=[\n",
    "        ( 'date',   '@date{%F}'            ),\n",
    "        ( 'close',  '$@{close}{%0.2f}' ), # use @{ } for field names with spaces\n",
    "    ],\n",
    "\n",
    "    formatters={\n",
    "        '@date'        : 'datetime', # use 'datetime' formatter for '@date' field\n",
    "        '@{close}' : 'printf',   # use 'printf' formatter for '@{adj close}' field\n",
    "                                     # use default 'numeral' formatter for other fields\n",
    "    },\n",
    "\n",
    "    # display a tooltip whenever the cursor is vertically in line with a glyph\n",
    "    # mode='vline'\n",
    ")\n",
    "p.add_tools(hover_tool)\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save\"\n",
    "\n",
    "select = figure(title=\"Drag the middle and edges of the selection box to change the range above\",\n",
    "                plot_height=130, plot_width=800, y_range=p.y_range, tools=TOOLS, \n",
    "                x_axis_type=\"datetime\", y_axis_type=None,\n",
    "                toolbar_location=None, background_fill_color=\"#efefef\")\n",
    "\n",
    "range_tool = RangeTool(x_range=tmp)\n",
    "range_tool.overlay.fill_color = \"navy\"\n",
    "range_tool.overlay.fill_alpha = 0.2\n",
    "\n",
    "select.line('date', 'close', source=source1)\n",
    "select.ygrid.grid_line_color = None\n",
    "select.add_tools(range_tool, hover_tool)\n",
    "select.toolbar.active_multi = range_tool\n",
    "\n",
    "# output_notebook()\n",
    "# show(column(p, select))\n",
    "save(column(p, select), filename=\"plots/lstm_next_price.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
