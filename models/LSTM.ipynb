{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Stock Market Data\n",
    "\n",
    "In this kernel, we will design and train the model we will use in our web app. We will develop a Long Short-Term Memory (LSTM) Neural Network and harness its capability to solve problems in time series. This model will take as input Closing Stock Prices of previous days and predict the next days Stock Prices.\n",
    "\n",
    "Most resources online showed how to train a LSTM model on a single company's historical stock market dataset. Yet I want a model I can use to predict prices for various companies on the Alfred web-app. So I will aggregate a lot of data on publicly traded companies and train a model that can capture live stock market patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib inline\n",
    "\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColumnDataSource, RangeTool, HoverTool\n",
    "from bokeh.plotting import figure, output_notebook, show, save\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same list of companies that can be studied on Alfred\n",
    "companies = pd.read_html('https://en.wikipedia.org/wiki/List_of_S'\n",
    "                         '%26P_500_companies')[0]\n",
    "# For the sake of the Proof Of Concept, we will use fewer companies than that\n",
    "companies = companies[['Symbol']][companies['GICS Sector'] == 'Information Technology'].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAPL'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a random company for evaluation\n",
    "index = int(np.random.random()*len(companies))\n",
    "eval_company = companies[index]\n",
    "companies = np.delete(companies, index)\n",
    "eval_company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first challenge posed to us is to format the data. The LSTM needs a window of historical data points and a window of target points. This function splits the data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape the data into strips of historical prices for the LSTM\n",
    "input_len = 30\n",
    "output_len = 1\n",
    "\n",
    "def split_data_prices_in_windows(df):\n",
    "    \"\"\"\n",
    "    Create series of \"input_len\" Closing prices (X) and its coresponding \"output_len\" price (Y).  \n",
    "    \"\"\"\n",
    "    LSTM_inputs = []\n",
    "    LSTM_outputs = []\n",
    "    for i in range(input_len, len(df)):\n",
    "        # Process the model's input sequence\n",
    "        historical_prices = df[i-input_len : i].copy()\n",
    "        LSTM_inputs.append(np.array(historical_prices))\n",
    "        \n",
    "        # Process the model's expected output sequence\n",
    "        target_price = df[i].copy()        \n",
    "        LSTM_outputs.append(np.array(target_price))\n",
    "        \n",
    "    LSTM_inputs = np.array(LSTM_inputs)\n",
    "    LSTM_outputs = np.array(LSTM_outputs)\n",
    "    \n",
    "    return LSTM_inputs, LSTM_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download all this data and store it in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# We will manually create the arrays with the first company before looping for the rest\n",
    "cmp = yf.download(companies[0])\n",
    "# Get the closing price into a train and test array\n",
    "train_set = cmp.iloc[:int(cmp.shape[0]*.80), 3:4].values\n",
    "test_set = cmp.iloc[int(cmp.shape[0]*.80):, 3:4].values\n",
    "# Get the closing price into format acceptable for the LSTM\n",
    "x_train, y_train = split_data_prices_in_windows(train_set)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1]))\n",
    "x_test, y_test = split_data_prices_in_windows(test_set)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1]))\n",
    "\n",
    "for company in companies[1:]:\n",
    "    cmp = yf.download(company)\n",
    "    # Get the closing price into a train and test array\n",
    "    train_set_tmp = cmp.iloc[:int(cmp.shape[0]*.80), 3:4].values\n",
    "    test_set_tmp = cmp.iloc[int(cmp.shape[0]*.80):, 3:4].values\n",
    "    # Get the closing price into format acceptable for the LSTM\n",
    "    x_train_tmp, y_train_tmp = split_data_prices_in_windows(train_set)\n",
    "    x_train_tmp = np.reshape(x_train_tmp, (x_train_tmp.shape[0], x_train_tmp.shape[1]))\n",
    "    x_test_tmp, y_test_tmp = split_data_prices_in_windows(test_set)\n",
    "    x_test_tmp = np.reshape(x_test_tmp, (x_test_tmp.shape[0], x_test_tmp.shape[1]))\n",
    "    # Gather the data points into a single array\n",
    "    x_train = np.concatenate((x_train, x_train_tmp))\n",
    "    x_test = np.concatenate((x_test, x_test_tmp))\n",
    "    y_train = np.concatenate((y_train, y_train_tmp))\n",
    "    y_test = np.concatenate((y_test, y_test_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have numerous company's historical stock market data, let us process it to facilitate the learning of the LSTM. Given the different scales of the companies, their stocks have different values. Let's scale the data according to the MinMaxScaler: normalize the data between (0, 1) based on the the overall maximum and minimum prices of all companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "total_max = x_train.max()\n",
    "total_min = x_train.min()\n",
    "\n",
    "x_train = (x_train - total_min) / (total_max - total_min)\n",
    "x_test = (x_test - total_min) / (total_max - total_min)\n",
    "y_train = (y_train - total_min) / (total_max - total_min)\n",
    "y_test = (y_test - total_min) / (total_max - total_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the train data to avoid bias due to the ordering of data.\n",
    "x_train, y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data for the LSTM model\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRScheduler(Callback):\n",
    "    '''Cosine annealing learning rate scheduler with periodic restarts.\n",
    "    # Usage\n",
    "        ```python\n",
    "            schedule = SGDRScheduler(min_lr=1e-5,\n",
    "                                     max_lr=1e-2,\n",
    "                                     steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                                     lr_decay=0.9,\n",
    "                                     cycle_length=5,\n",
    "                                     mult_factor=1.5)\n",
    "            model.fit(X_train, Y_train, epochs=100, callbacks=[schedule])\n",
    "        ```\n",
    "        \n",
    "    # Arguments\n",
    "        min_lr: The lower bound of the learning rate range for the experiment.\n",
    "        max_lr: The upper bound of the learning rate range for the experiment.\n",
    "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`. \n",
    "        lr_decay: Reduce the max_lr after the completion of each cycle.\n",
    "                  Ex. To reduce the max_lr by 20% after each cycle, set this value to 0.8.\n",
    "        cycle_length: Initial number of epochs in a cycle.\n",
    "        mult_factor: Scale epochs_to_restart after each full cycle completion.\n",
    "        \n",
    "    # References\n",
    "        Blog post: jeremyjordan.me/nn-learning-rate\n",
    "        Original paper: http://arxiv.org/abs/1608.03983\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 min_lr,\n",
    "                 max_lr,\n",
    "                 steps_per_epoch,\n",
    "                 lr_decay=1,\n",
    "                 cycle_length=10,\n",
    "                 mult_factor=2):\n",
    "\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.lr_decay = lr_decay\n",
    "\n",
    "        self.batch_since_restart = 0\n",
    "        self.next_restart = cycle_length\n",
    "\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "        self.cycle_length = cycle_length\n",
    "        self.mult_factor = mult_factor\n",
    "\n",
    "        self.history = {}\n",
    "\n",
    "    def clr(self):\n",
    "        '''Calculate the learning rate.'''\n",
    "        fraction_to_restart = self.batch_since_restart / (self.steps_per_epoch * self.cycle_length)\n",
    "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(fraction_to_restart * np.pi))\n",
    "        return lr\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
    "        logs = logs or {}\n",
    "        K.set_value(self.model.optimizer.lr, self.max_lr)\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        '''Record previous batch statistics and update the learning rate.'''\n",
    "        logs = logs or {}\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "\n",
    "        self.batch_since_restart += 1\n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        '''Check for end of current cycle, apply restarts when necessary.'''\n",
    "        if epoch + 1 == self.next_restart:\n",
    "            self.batch_since_restart = 0\n",
    "            self.cycle_length = np.ceil(self.cycle_length * self.mult_factor)\n",
    "            self.next_restart += self.cycle_length\n",
    "            self.max_lr *= self.lr_decay\n",
    "            self.best_weights = self.model.get_weights()\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        '''Set weights to the values from the end of the most recent cycle for best performance.'''\n",
    "        self.model.set_weights(self.best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def __init__(self):\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def on_batch_end(self, epoch, logs={}):\n",
    "        self.loss.append(logs.get('loss'))\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.val_loss.append(logs.get('val_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(input_shape, output_shape, neurons, dropout):\n",
    "    x = Input(shape=input_shape)\n",
    "    hidden = LSTM(neurons, return_sequences=True)(x)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    hidden = LSTM(neurons, return_sequences=True)(x)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    hidden = LSTM(neurons, return_sequences=True)(x)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    hidden = LSTM(neurons, return_sequences=False)(hidden)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    y = Dense(output_shape, activation='linear')(hidden)\n",
    "    return Model(inputs=x, outputs=y)\n",
    "\n",
    "model = LSTM_model((input_len, 1), output_len, 50, 0.2)\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "\n",
    "model.compile(optimizer=optimizer, metrics=['mse'], loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2122/2122 [==============================] - 11s 5ms/step - loss: 2.0121 - mse: 2.0121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0121452808380127, 2.0121452808380127]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Create the Learning Rate Scheduler Callback\n",
    "schedule = SGDRScheduler(min_lr=1e-3,\n",
    "                         max_lr=1e-2,\n",
    "                         steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                         lr_decay=0.9,\n",
    "                         cycle_length= 3,\n",
    "                         mult_factor=1.5)\n",
    "\n",
    "# Callback function to graph losses\n",
    "lh = LossHistory()\n",
    "\n",
    "# Callback function to stopp when the validation loss stagnates\n",
    "es = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8685/8685 [==============================] - 130s 15ms/step - loss: 7.4904e-04 - mse: 7.4904e-04 - val_loss: 0.0578 - val_mse: 0.0578\n",
      "Epoch 2/100\n",
      "8685/8685 [==============================] - 121s 14ms/step - loss: 5.5061e-04 - mse: 5.5061e-04 - val_loss: 0.1381 - val_mse: 0.1381\n",
      "Epoch 3/100\n",
      "8685/8685 [==============================] - 119s 14ms/step - loss: 4.9954e-04 - mse: 4.9954e-04 - val_loss: 0.1913 - val_mse: 0.1913\n",
      "Epoch 4/100\n",
      "8685/8685 [==============================] - 130s 15ms/step - loss: 4.7538e-04 - mse: 4.7538e-04 - val_loss: 0.0450 - val_mse: 0.0450\n",
      "Epoch 5/100\n",
      "8685/8685 [==============================] - 136s 16ms/step - loss: 4.6186e-04 - mse: 4.6186e-04 - val_loss: 0.0754 - val_mse: 0.0754\n",
      "Epoch 6/100\n",
      "8685/8685 [==============================] - 123s 14ms/step - loss: 4.5563e-04 - mse: 4.5563e-04 - val_loss: 0.0281 - val_mse: 0.0281\n",
      "Epoch 7/100\n",
      "8685/8685 [==============================] - 124s 14ms/step - loss: 4.5030e-04 - mse: 4.5030e-04 - val_loss: 0.0751 - val_mse: 0.0751\n",
      "Epoch 8/100\n",
      "8685/8685 [==============================] - 124s 14ms/step - loss: 4.4846e-04 - mse: 4.4846e-04 - val_loss: 0.2476 - val_mse: 0.2476\n",
      "Epoch 9/100\n",
      "8685/8685 [==============================] - 121s 14ms/step - loss: 4.3839e-04 - mse: 4.3839e-04 - val_loss: 0.2541 - val_mse: 0.2541\n",
      "Epoch 10/100\n",
      "8685/8685 [==============================] - 122s 14ms/step - loss: 4.3888e-04 - mse: 4.3888e-04 - val_loss: 0.2755 - val_mse: 0.2755\n",
      "Epoch 11/100\n",
      "8685/8685 [==============================] - 122s 14ms/step - loss: 4.3743e-04 - mse: 4.3743e-04 - val_loss: 0.4748 - val_mse: 0.4748\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, validation_data = (x_test, y_test),\n",
    "          epochs = epoch_size, batch_size = batch_size, callbacks=[lh, schedule, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"checkpoints/lstm_next_price_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"checkpoints/lstm_next_prices.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2122/2122 [==============================] - 10s 5ms/step - loss: 0.2476 - mse: 0.2476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24756264686584473, 0.24756264686584473]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(16,6))\n",
    "ax1.plot(lh.loss)\n",
    "ax1.set_title('Train Loss')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_xlabel('Batch')\n",
    "ax2.plot(lh.val_loss)\n",
    "ax2.set_title('Validation Loss')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on unseen stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.100266</td>\n",
       "      <td>469033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.095035</td>\n",
       "      <td>175884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.088059</td>\n",
       "      <td>105728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17</th>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.090239</td>\n",
       "      <td>86441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18</th>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.092855</td>\n",
       "      <td>73449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>120.500000</td>\n",
       "      <td>121.989998</td>\n",
       "      <td>116.050003</td>\n",
       "      <td>116.320000</td>\n",
       "      <td>116.320000</td>\n",
       "      <td>154515300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10</th>\n",
       "      <td>115.550003</td>\n",
       "      <td>117.589996</td>\n",
       "      <td>114.129997</td>\n",
       "      <td>115.970001</td>\n",
       "      <td>115.970001</td>\n",
       "      <td>138023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-11</th>\n",
       "      <td>117.190002</td>\n",
       "      <td>119.629997</td>\n",
       "      <td>116.440002</td>\n",
       "      <td>119.489998</td>\n",
       "      <td>119.489998</td>\n",
       "      <td>112295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-12</th>\n",
       "      <td>119.620003</td>\n",
       "      <td>120.529999</td>\n",
       "      <td>118.570000</td>\n",
       "      <td>119.209999</td>\n",
       "      <td>119.209999</td>\n",
       "      <td>103162300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-13</th>\n",
       "      <td>119.440002</td>\n",
       "      <td>119.669998</td>\n",
       "      <td>117.870003</td>\n",
       "      <td>119.260002</td>\n",
       "      <td>119.260002</td>\n",
       "      <td>81581900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10067 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "1980-12-12    0.128348    0.128906    0.128348    0.128348    0.100266   \n",
       "1980-12-15    0.122210    0.122210    0.121652    0.121652    0.095035   \n",
       "1980-12-16    0.113281    0.113281    0.112723    0.112723    0.088059   \n",
       "1980-12-17    0.115513    0.116071    0.115513    0.115513    0.090239   \n",
       "1980-12-18    0.118862    0.119420    0.118862    0.118862    0.092855   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2020-11-09  120.500000  121.989998  116.050003  116.320000  116.320000   \n",
       "2020-11-10  115.550003  117.589996  114.129997  115.970001  115.970001   \n",
       "2020-11-11  117.190002  119.629997  116.440002  119.489998  119.489998   \n",
       "2020-11-12  119.620003  120.529999  118.570000  119.209999  119.209999   \n",
       "2020-11-13  119.440002  119.669998  117.870003  119.260002  119.260002   \n",
       "\n",
       "               Volume  \n",
       "1980-12-12  469033600  \n",
       "1980-12-15  175884800  \n",
       "1980-12-16  105728000  \n",
       "1980-12-17   86441600  \n",
       "1980-12-18   73449600  \n",
       "...               ...  \n",
       "2020-11-09  154515300  \n",
       "2020-11-10  138023400  \n",
       "2020-11-11  112295000  \n",
       "2020-11-12  103162300  \n",
       "2020-11-13   81581900  \n",
       "\n",
       "[10067 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = yf.download(eval_company)\n",
    "df.index.name = None\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = df.iloc[:, 3:4].values\n",
    "\n",
    "x_eval, y_eval = split_data_prices_in_windows(eval_set)\n",
    "x_eval = np.reshape(x_eval, (x_eval.shape[0], x_eval.shape[1]))\n",
    "\n",
    "x_eval = (x_eval - total_min) / (total_max - total_min)\n",
    "y_eval = (y_eval - total_min) / (total_max - total_min)\n",
    "x_eval = np.reshape(x_eval, (x_eval.shape[0], x_eval.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = model.predict(x_eval)\n",
    "# Transform the predicted data back to stock prices\n",
    "predicted_stock_price = predicted_stock_price * (total_max - total_min) + total_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fournierp/.local/share/virtualenvs/alfred-Mlefol6Z/lib/python3.8/site-packages/bokeh/io/saving.py:126: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
      "  warn(\"save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\")\n",
      "/home/fournierp/.local/share/virtualenvs/alfred-Mlefol6Z/lib/python3.8/site-packages/bokeh/io/saving.py:139: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
      "  warn(\"save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/fournierp/Documents/alfred/models/plots/lstm_next_price.html'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(eval_set, index=df.iloc[:, 3:4].index, columns=[\"Close\"])\n",
    "df2 = pd.DataFrame(predicted_stock_price, index= df.iloc[30:, 3:4].index, columns=[\"Close\"])\n",
    "df1[\"Date\"] = pd.to_datetime(df1.index)\n",
    "df2[\"Date\"] = pd.to_datetime(df2.index)\n",
    "dates1 = df1['Date']\n",
    "dates2 = df2['Date']\n",
    "source1 = ColumnDataSource(data=dict(date=dates1, close=df1['Close']))\n",
    "source2 = ColumnDataSource(data=dict(date=dates2, close=df2['Close']))\n",
    "\n",
    "p = figure(plot_height=300, plot_width=800, tools=\"xpan\", toolbar_location=None,\n",
    "           x_axis_type=\"datetime\", x_axis_location=\"above\",\n",
    "           background_fill_color=\"#efefef\", x_range=(dates1[dates1.index[-100]], dates1[dates1.index[-1]]))\n",
    "tmp = p.x_range # Store it before adding multiple lines\n",
    "p.line('date', 'close', source=source1, legend_label='Real Stock Price', color='green')\n",
    "p.line('date', 'close', source=source2, legend_label='Predicted Stock Price', color='blue')\n",
    "\n",
    "p.yaxis.axis_label = 'Price'\n",
    "\n",
    "\n",
    "hover_tool = HoverTool(\n",
    "    tooltips=[\n",
    "        ( 'date',   '@date{%F}'            ),\n",
    "        ( 'close',  '$@{close}{%0.2f}' ), # use @{ } for field names with spaces\n",
    "    ],\n",
    "\n",
    "    formatters={\n",
    "        '@date'        : 'datetime', # use 'datetime' formatter for '@date' field\n",
    "        '@{close}' : 'printf',   # use 'printf' formatter for '@{adj close}' field\n",
    "                                     # use default 'numeral' formatter for other fields\n",
    "    },\n",
    "\n",
    "    # display a tooltip whenever the cursor is vertically in line with a glyph\n",
    "    # mode='vline'\n",
    ")\n",
    "p.add_tools(hover_tool)\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save\"\n",
    "\n",
    "select = figure(title=\"Drag the middle and edges of the selection box to change the range above\",\n",
    "                plot_height=130, plot_width=800, y_range=p.y_range, tools=TOOLS, \n",
    "                x_axis_type=\"datetime\", y_axis_type=None,\n",
    "                toolbar_location=None, background_fill_color=\"#efefef\")\n",
    "\n",
    "range_tool = RangeTool(x_range=tmp)\n",
    "range_tool.overlay.fill_color = \"navy\"\n",
    "range_tool.overlay.fill_alpha = 0.2\n",
    "\n",
    "select.line('date', 'close', source=source1)\n",
    "select.ygrid.grid_line_color = None\n",
    "select.add_tools(range_tool, hover_tool)\n",
    "select.toolbar.active_multi = range_tool\n",
    "\n",
    "# output_notebook()\n",
    "# show(column(p, select))\n",
    "save(column(p, select), filename=\"plots/lstm_next_price.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
