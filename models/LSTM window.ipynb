{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Stock Market Data\n",
    "\n",
    "In this kernel, we will design and train the model we will use in our web app. We will develop a Long Short-Term Memory (LSTM) Neural Network and harness its capability to solve problems in time series. This model will take as input Closing Stock Prices of previous days and predict the next days Stock Prices.\n",
    "\n",
    "Most resources online showed how to train a LSTM model on a single company's historical stock market dataset. Yet I want a model I can use to predict prices for various companies on the Alfred web-app. So I will aggregate a lot of data on publicly traded companies and train a model that can capture live stock market patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib inline\n",
    "\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColumnDataSource, RangeTool, HoverTool\n",
    "from bokeh.plotting import figure, output_notebook, show, save\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same list of companies that can be studied on Alfred\n",
    "companies = pd.read_html('https://en.wikipedia.org/wiki/List_of_S'\n",
    "                         '%26P_500_companies')[0]\n",
    "# For the sake of the Proof Of Concept, we will use fewer companies than that\n",
    "companies = companies[['Symbol']][companies['GICS Sector'] == 'Information Technology'].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAPL'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a random company for evaluation\n",
    "index = int(np.random.random()*len(companies))\n",
    "eval_company = companies[index]\n",
    "companies = np.delete(companies, index)\n",
    "eval_company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first challenge posed to us is to format the data. The LSTM needs a window of historical data points and a window of target points. This function splits the data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape the data into strips of historical prices for the LSTM\n",
    "input_len = 30\n",
    "output_len = 5\n",
    "\n",
    "def split_data_prices_in_windows(df):\n",
    "    \"\"\"\n",
    "    Create series of \"input_len\" Closing prices (X) and its coresponding \"output_len\" price (Y).  \n",
    "    \"\"\"\n",
    "    LSTM_inputs = []\n",
    "    LSTM_outputs = []\n",
    "    for i in range(input_len, len(df)):\n",
    "        # Process the model's input sequence\n",
    "        historical_prices = df[i-input_len : i].copy()\n",
    "        LSTM_inputs.append(np.array(historical_prices))\n",
    "        \n",
    "        # Process the model's expected output sequence\n",
    "        target_price = df[i].copy()        \n",
    "        LSTM_outputs.append(np.array(target_price))\n",
    "        \n",
    "    LSTM_inputs = np.array(LSTM_inputs)\n",
    "    LSTM_outputs = np.array(LSTM_outputs)\n",
    "    \n",
    "    return LSTM_inputs, LSTM_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download all this data and store it in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# We will manually create the arrays with the first company before looping for the rest\n",
    "cmp = yf.download(companies[0])\n",
    "# Get the closing price into a train and test array\n",
    "train_set = cmp.iloc[:int(cmp.shape[0]*.80), 3:4].values\n",
    "test_set = cmp.iloc[int(cmp.shape[0]*.80):, 3:4].values\n",
    "# Get the closing price into format acceptable for the LSTM\n",
    "x_train, y_train = split_data_prices_in_windows(train_set)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1]))\n",
    "x_test, y_test = split_data_prices_in_windows(test_set)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1]))\n",
    "\n",
    "for company in companies[1:]:\n",
    "    cmp = yf.download(company)\n",
    "    # Get the closing price into a train and test array\n",
    "    train_set_tmp = cmp.iloc[:int(cmp.shape[0]*.80), 3:4].values\n",
    "    test_set_tmp = cmp.iloc[int(cmp.shape[0]*.80):, 3:4].values\n",
    "    # Get the closing price into format acceptable for the LSTM\n",
    "    x_train_tmp, y_train_tmp = split_data_prices_in_windows(train_set)\n",
    "    x_train_tmp = np.reshape(x_train_tmp, (x_train_tmp.shape[0], x_train_tmp.shape[1]))\n",
    "    x_test_tmp, y_test_tmp = split_data_prices_in_windows(test_set)\n",
    "    x_test_tmp = np.reshape(x_test_tmp, (x_test_tmp.shape[0], x_test_tmp.shape[1]))\n",
    "    # Gather the data points into a single array\n",
    "    x_train = np.concatenate((x_train, x_train_tmp))\n",
    "    x_test = np.concatenate((x_test, x_test_tmp))\n",
    "    y_train = np.concatenate((y_train, y_train_tmp))\n",
    "    y_test = np.concatenate((y_test, y_test_tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have numerous company's historical stock market data, let us process it to facilitate the learning of the LSTM. Given the different scales of the companies, their stocks have different values. Let's scale the data according to the MinMaxScaler: normalize the data between (0, 1) based on the the overall maximum and minimum prices of all companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "total_max = x_train.max()\n",
    "total_min = x_train.min()\n",
    "\n",
    "x_train = (x_train - total_min) / (total_max - total_min)\n",
    "x_test = (x_test - total_min) / (total_max - total_min)\n",
    "y_train = (y_train - total_min) / (total_max - total_min)\n",
    "y_test = (y_test - total_min) / (total_max - total_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scaler information to inverse transform data in the web app\n",
    "model_data = {\n",
    "    'total_max' : total_max,\n",
    "    'total_min' : total_min,\n",
    "}\n",
    "\n",
    "with open('data_win.txt', 'w') as outfile:\n",
    "    json.dump(model_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the train data to avoid bias due to the ordering of data.\n",
    "x_train, y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data for the LSTM model\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRScheduler(Callback):\n",
    "    '''Cosine annealing learning rate scheduler with periodic restarts.\n",
    "    # Usage\n",
    "        ```python\n",
    "            schedule = SGDRScheduler(min_lr=1e-5,\n",
    "                                     max_lr=1e-2,\n",
    "                                     steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                                     lr_decay=0.9,\n",
    "                                     cycle_length=5,\n",
    "                                     mult_factor=1.5)\n",
    "            model.fit(X_train, Y_train, epochs=100, callbacks=[schedule])\n",
    "        ```\n",
    "        \n",
    "    # Arguments\n",
    "        min_lr: The lower bound of the learning rate range for the experiment.\n",
    "        max_lr: The upper bound of the learning rate range for the experiment.\n",
    "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`. \n",
    "        lr_decay: Reduce the max_lr after the completion of each cycle.\n",
    "                  Ex. To reduce the max_lr by 20% after each cycle, set this value to 0.8.\n",
    "        cycle_length: Initial number of epochs in a cycle.\n",
    "        mult_factor: Scale epochs_to_restart after each full cycle completion.\n",
    "        \n",
    "    # References\n",
    "        Blog post: jeremyjordan.me/nn-learning-rate\n",
    "        Original paper: http://arxiv.org/abs/1608.03983\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 min_lr,\n",
    "                 max_lr,\n",
    "                 steps_per_epoch,\n",
    "                 lr_decay=1,\n",
    "                 cycle_length=10,\n",
    "                 mult_factor=2):\n",
    "\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.lr_decay = lr_decay\n",
    "\n",
    "        self.batch_since_restart = 0\n",
    "        self.next_restart = cycle_length\n",
    "\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "        self.cycle_length = cycle_length\n",
    "        self.mult_factor = mult_factor\n",
    "\n",
    "        self.history = {}\n",
    "\n",
    "    def clr(self):\n",
    "        '''Calculate the learning rate.'''\n",
    "        fraction_to_restart = self.batch_since_restart / (self.steps_per_epoch * self.cycle_length)\n",
    "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(fraction_to_restart * np.pi))\n",
    "        return lr\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
    "        logs = logs or {}\n",
    "        K.set_value(self.model.optimizer.lr, self.max_lr)\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        '''Record previous batch statistics and update the learning rate.'''\n",
    "        logs = logs or {}\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "\n",
    "        self.batch_since_restart += 1\n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        '''Check for end of current cycle, apply restarts when necessary.'''\n",
    "        if epoch + 1 == self.next_restart:\n",
    "            self.batch_since_restart = 0\n",
    "            self.cycle_length = np.ceil(self.cycle_length * self.mult_factor)\n",
    "            self.next_restart += self.cycle_length\n",
    "            self.max_lr *= self.lr_decay\n",
    "            self.best_weights = self.model.get_weights()\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        '''Set weights to the values from the end of the most recent cycle for best performance.'''\n",
    "        self.model.set_weights(self.best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def __init__(self):\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def on_batch_end(self, epoch, logs={}):\n",
    "        self.loss.append(logs.get('loss'))\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.val_loss.append(logs.get('val_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(input_shape, output_shape, neurons, dropout):\n",
    "    x = Input(shape=input_shape)\n",
    "    hidden = LSTM(neurons, return_sequences=True)(x)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    hidden = LSTM(neurons, return_sequences=True)(x)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    hidden = LSTM(neurons, return_sequences=True)(x)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    hidden = LSTM(neurons, return_sequences=False)(hidden)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    y = Dense(output_shape, activation='linear')(hidden)\n",
    "    return Model(inputs=x, outputs=y)\n",
    "\n",
    "model = LSTM_model((input_len, 1), output_len, 50, 0.2)\n",
    "\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "\n",
    "model.compile(optimizer=optimizer, metrics=['mse'], loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 [==============================] - 16s 8ms/step - loss: 2.0945 - mse: 2.0945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.094503164291382, 2.094503164291382]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 100\n",
    "batch_size = 32\n",
    "\n",
    "# Create the Learning Rate Scheduler Callback\n",
    "schedule = SGDRScheduler(min_lr=1e-3,\n",
    "                         max_lr=1e-2,\n",
    "                         steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                         lr_decay=0.9,\n",
    "                         cycle_length= 3,\n",
    "                         mult_factor=1.5)\n",
    "\n",
    "# Callback function to graph losses\n",
    "lh = LossHistory()\n",
    "\n",
    "# Callback function to stopp when the validation loss stagnates\n",
    "es = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8618/8618 [==============================] - 283s 33ms/step - loss: 8.6850e-04 - mse: 8.6850e-04 - val_loss: 0.0876 - val_mse: 0.0876\n",
      "Epoch 2/100\n",
      "8618/8618 [==============================] - 282s 33ms/step - loss: 5.5591e-04 - mse: 5.5591e-04 - val_loss: 0.1556 - val_mse: 0.1556\n",
      "Epoch 3/100\n",
      "8618/8618 [==============================] - 282s 33ms/step - loss: 5.0362e-04 - mse: 5.0362e-04 - val_loss: 0.2006 - val_mse: 0.2006\n",
      "Epoch 4/100\n",
      "8618/8618 [==============================] - 276s 32ms/step - loss: 4.7310e-04 - mse: 4.7310e-04 - val_loss: 0.3215 - val_mse: 0.3215\n",
      "Epoch 5/100\n",
      "8618/8618 [==============================] - 275s 32ms/step - loss: 4.6211e-04 - mse: 4.6211e-04 - val_loss: 0.2823 - val_mse: 0.2823\n",
      "Epoch 6/100\n",
      "8618/8618 [==============================] - 275s 32ms/step - loss: 4.4895e-04 - mse: 4.4895e-04 - val_loss: 0.4704 - val_mse: 0.4704\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data = (x_test, y_test),\n",
    "          epochs = epoch_size, batch_size = batch_size, callbacks=[lh, schedule, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"checkpoints/lstm_next_price_win_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"checkpoints/lstm_next_prices_win.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/2055 [==============================] - 16s 8ms/step - loss: 0.2006 - mse: 0.2006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2005816102027893, 0.2005816102027893]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(16,6))\n",
    "ax1.plot(lh.loss)\n",
    "ax1.set_title('Train Loss')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_xlabel('Batch')\n",
    "ax2.plot(lh.val_loss)\n",
    "ax2.set_title('Validation Loss')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on unseen stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.100266</td>\n",
       "      <td>469033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.095035</td>\n",
       "      <td>175884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.088059</td>\n",
       "      <td>105728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17</th>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.090239</td>\n",
       "      <td>86441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18</th>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.092855</td>\n",
       "      <td>73449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>120.500000</td>\n",
       "      <td>121.989998</td>\n",
       "      <td>116.050003</td>\n",
       "      <td>116.320000</td>\n",
       "      <td>116.320000</td>\n",
       "      <td>154515300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10</th>\n",
       "      <td>115.550003</td>\n",
       "      <td>117.589996</td>\n",
       "      <td>114.129997</td>\n",
       "      <td>115.970001</td>\n",
       "      <td>115.970001</td>\n",
       "      <td>138023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-11</th>\n",
       "      <td>117.190002</td>\n",
       "      <td>119.629997</td>\n",
       "      <td>116.440002</td>\n",
       "      <td>119.489998</td>\n",
       "      <td>119.489998</td>\n",
       "      <td>112295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-12</th>\n",
       "      <td>119.620003</td>\n",
       "      <td>120.529999</td>\n",
       "      <td>118.570000</td>\n",
       "      <td>119.209999</td>\n",
       "      <td>119.209999</td>\n",
       "      <td>103162300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-13</th>\n",
       "      <td>119.440002</td>\n",
       "      <td>119.669998</td>\n",
       "      <td>117.870003</td>\n",
       "      <td>119.260002</td>\n",
       "      <td>119.260002</td>\n",
       "      <td>81581900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10067 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "1980-12-12    0.128348    0.128906    0.128348    0.128348    0.100266   \n",
       "1980-12-15    0.122210    0.122210    0.121652    0.121652    0.095035   \n",
       "1980-12-16    0.113281    0.113281    0.112723    0.112723    0.088059   \n",
       "1980-12-17    0.115513    0.116071    0.115513    0.115513    0.090239   \n",
       "1980-12-18    0.118862    0.119420    0.118862    0.118862    0.092855   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2020-11-09  120.500000  121.989998  116.050003  116.320000  116.320000   \n",
       "2020-11-10  115.550003  117.589996  114.129997  115.970001  115.970001   \n",
       "2020-11-11  117.190002  119.629997  116.440002  119.489998  119.489998   \n",
       "2020-11-12  119.620003  120.529999  118.570000  119.209999  119.209999   \n",
       "2020-11-13  119.440002  119.669998  117.870003  119.260002  119.260002   \n",
       "\n",
       "               Volume  \n",
       "1980-12-12  469033600  \n",
       "1980-12-15  175884800  \n",
       "1980-12-16  105728000  \n",
       "1980-12-17   86441600  \n",
       "1980-12-18   73449600  \n",
       "...               ...  \n",
       "2020-11-09  154515300  \n",
       "2020-11-10  138023400  \n",
       "2020-11-11  112295000  \n",
       "2020-11-12  103162300  \n",
       "2020-11-13   81581900  \n",
       "\n",
       "[10067 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = yf.download(eval_company)\n",
    "df.index.name = None\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = df.iloc[:, 3:4].values\n",
    "\n",
    "x_eval, y_eval = split_data_prices_in_windows(eval_set)\n",
    "x_eval = np.reshape(x_eval, (x_eval.shape[0], x_eval.shape[1]))\n",
    "\n",
    "x_eval = (x_eval - total_min) / (total_max - total_min)\n",
    "y_eval = (y_eval - total_min) / (total_max - total_min)\n",
    "x_eval = np.reshape(x_eval, (x_eval.shape[0], x_eval.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = model.predict(x_eval)\n",
    "# Transform the predicted data back to stock prices\n",
    "predicted_stock_price = predicted_stock_price * (total_max - total_min) + total_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fournierp/.local/share/virtualenvs/alfred-Mlefol6Z/lib/python3.8/site-packages/bokeh/io/saving.py:126: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
      "  warn(\"save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\")\n",
      "/home/fournierp/.local/share/virtualenvs/alfred-Mlefol6Z/lib/python3.8/site-packages/bokeh/io/saving.py:139: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
      "  warn(\"save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/fournierp/Documents/alfred/models/plots/lstm_next_price_win.html'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(eval_set, index=df.iloc[:, 3:4].index, columns=[\"Close\"])\n",
    "df1[\"Date\"] = pd.to_datetime(df1.index)\n",
    "dates1 = df1['Date']\n",
    "source1 = ColumnDataSource(data=dict(date=dates1, close=df1['Close']))\n",
    "\n",
    "p = figure(plot_height=300, plot_width=800, tools=\"xpan\", toolbar_location=None,\n",
    "           x_axis_type=\"datetime\", x_axis_location=\"above\",\n",
    "           background_fill_color=\"#efefef\", x_range=(dates1[dates1.index[-100]], dates1[dates1.index[-1]]))\n",
    "tmp = p.x_range # Store it before adding multiple lines\n",
    "p.line('date', 'close', source=source1, legend_label='Real Stock Price', color='green')\n",
    "\n",
    "for i, y_pred in enumerate(predicted_stock_price[::output_len]):\n",
    "    if df1.iloc[input_len+output_len*(i):input_len+output_len*(i+1)].index.shape[0] != output_len:\n",
    "        continue\n",
    "    df2 = pd.DataFrame(y_pred,\n",
    "                       index=df1.iloc[input_len+output_len*(i):input_len+output_len*(i+1)].index,\n",
    "                       columns=[\"Close\"])\n",
    "    df2[\"Date\"] = pd.to_datetime(df2.index)\n",
    "    source2 = ColumnDataSource(data=dict(date=df2['Date'], close=df2['Close']))\n",
    "    p.line('date', 'close', source=source2, legend_label='Predicted Stock Price', color='red')\n",
    "\n",
    "p.yaxis.axis_label = 'Price'\n",
    "\n",
    "hover_tool = HoverTool(\n",
    "    tooltips=[\n",
    "        ( 'date',   '@date{%F}'            ),\n",
    "        ( 'close',  '$@{close}{%0.2f}' ), # use @{ } for field names with spaces\n",
    "    ],\n",
    "\n",
    "    formatters={\n",
    "        '@date'        : 'datetime', # use 'datetime' formatter for '@date' field\n",
    "        '@{close}' : 'printf',   # use 'printf' formatter for '@{adj close}' field\n",
    "                                     # use default 'numeral' formatter for other fields\n",
    "    },\n",
    "\n",
    "    # display a tooltip whenever the cursor is vertically in line with a glyph\n",
    "    # mode='vline'\n",
    ")\n",
    "p.add_tools(hover_tool)\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save\"\n",
    "\n",
    "select = figure(title=\"Drag the middle and edges of the selection box to change the range above\",\n",
    "                plot_height=130, plot_width=800, y_range=p.y_range, tools=TOOLS, \n",
    "                x_axis_type=\"datetime\", y_axis_type=None,\n",
    "                toolbar_location=None, background_fill_color=\"#efefef\")\n",
    "\n",
    "range_tool = RangeTool(x_range=tmp)\n",
    "range_tool.overlay.fill_color = \"navy\"\n",
    "range_tool.overlay.fill_alpha = 0.2\n",
    "\n",
    "select.line('date', 'close', source=source1)\n",
    "select.ygrid.grid_line_color = None\n",
    "select.add_tools(range_tool, hover_tool)\n",
    "select.toolbar.active_multi = range_tool\n",
    "\n",
    "# output_notebook()\n",
    "# show(column(p, select))\n",
    "save(column(p, select), filename=\"plots/lstm_next_price_win.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
