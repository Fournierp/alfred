{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Stock Market Data\n",
    "\n",
    "In this kernel, we will design and train the model we will use in our web app. We will develop a Long Short-Term Memory (LSTM) Neural Network and harness its capability to solve problems in time series. This model will take as input Closing Stock Prices of previous days and predict the next days Stock Prices.\n",
    "\n",
    "Most resources online showed how to train a LSTM model on a single company's historical stock market dataset. Yet I want a model I can use to predict prices for various companies on the Alfred web-app. So I will aggregate a lot of data on publicly traded companies and train a model that can capture live stock market patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib inline\n",
    "\n",
    "from bokeh.layouts import column\n",
    "from bokeh.models import ColumnDataSource, RangeTool, HoverTool\n",
    "from bokeh.plotting import figure, output_notebook, show, save\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the same list of companies that can be studied on Alfred\n",
    "companies = pd.read_html('https://en.wikipedia.org/wiki/List_of_S'\n",
    "                         '%26P_500_companies')[0]\n",
    "# For the sake of the Proof Of Concept, we will use fewer companies than that\n",
    "companies = companies[['Symbol']][companies['GICS Sector'] == 'Information Technology'].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AAPL'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a random company for evaluation\n",
    "index = int(np.random.random()*len(companies))\n",
    "eval_company = companies[index]\n",
    "companies = np.delete(companies, index)\n",
    "eval_company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first challenge posed to us is to format the data. The LSTM needs a window of historical data points and a window of target points. This function splits the data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape the data into strips of historical prices for the LSTM\n",
    "input_len = 30\n",
    "output_len = 5\n",
    "\n",
    "def split_data_prices_in_windows(df):\n",
    "    \"\"\"\n",
    "    Create series of \"input_len\" Closing prices (X) and its coresponding \"output_len\" price (Y).  \n",
    "    \"\"\"\n",
    "    LSTM_inputs = []\n",
    "    LSTM_outputs = []\n",
    "    for i in range(input_len, len(df)):\n",
    "        # Process the model's input sequence\n",
    "        historical_prices = df[i-input_len : i].copy()\n",
    "        \n",
    "        # Process the model's expected output sequence\n",
    "        target_price = df[i:i+output_len].copy()       \n",
    "        if len(target_price) != output_len:\n",
    "            continue\n",
    "            \n",
    "        LSTM_inputs.append(np.array(historical_prices))\n",
    "        LSTM_outputs.append(np.array(target_price))\n",
    "        \n",
    "    LSTM_inputs = np.array(LSTM_inputs)\n",
    "    LSTM_outputs = np.array(LSTM_outputs)\n",
    "    \n",
    "    return LSTM_inputs, LSTM_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download all this data and store it in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# We will manually create the arrays with the first company before looping for the rest\n",
    "cmp = yf.download(companies[0])\n",
    "# Get the closing price into a train array\n",
    "train_set = cmp.iloc[:, 3:4].values\n",
    "# Get the closing price into format acceptable for the LSTM\n",
    "x_train, y_train = split_data_prices_in_windows(train_set)\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1]))\n",
    "\n",
    "for company in companies[1:]:\n",
    "    cmp = yf.download(company)\n",
    "    # Get the closing price into a train\n",
    "    train_set_tmp = cmp.iloc[:, 3:4].values\n",
    "    # Get the closing price into format acceptable for the LSTM\n",
    "    x_train_tmp, y_train_tmp = split_data_prices_in_windows(train_set)\n",
    "    x_train_tmp = np.reshape(x_train_tmp, (x_train_tmp.shape[0], x_train_tmp.shape[1]))\n",
    "    # Gather the data points into a single array\n",
    "    x_train = np.concatenate((x_train, x_train_tmp))\n",
    "    y_train = np.concatenate((y_train, y_train_tmp))\n",
    "\n",
    "# Make the test array with the randomly selected company\n",
    "df = yf.download(eval_company)\n",
    "# Get the closing price into a test array\n",
    "test_set = df.iloc[:, 3:4].values\n",
    "x_test, y_test = split_data_prices_in_windows(test_set)\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have numerous company's historical stock market data, let us process it to facilitate the learning of the LSTM. Given the different scales of the companies, their stocks have different values. Let's scale the data according to the MinMaxScaler: normalize the data between (0, 1) based on the the overall maximum and minimum prices of all companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "total_max = x_train.max()\n",
    "total_min = x_train.min()\n",
    "\n",
    "x_train = (x_train - total_min) / (total_max - total_min)\n",
    "x_test = (x_test - total_min) / (total_max - total_min)\n",
    "y_train = (y_train - total_min) / (total_max - total_min)\n",
    "y_test = (y_test - total_min) / (total_max - total_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save scaler information to inverse transform data in the web app\n",
    "model_data = {\n",
    "    'total_max' : total_max,\n",
    "    'total_min' : total_min,\n",
    "    'input_len' : input_len,\n",
    "    'output_len' : output_len,\n",
    "}\n",
    "\n",
    "with open('checkpoints/data_win.txt', 'w') as outfile:\n",
    "    json.dump(model_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the train data to avoid bias due to the ordering of data.\n",
    "x_train, y_train = shuffle(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the data for the LSTM model\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDRScheduler(Callback):\n",
    "    '''Cosine annealing learning rate scheduler with periodic restarts.\n",
    "    # Usage\n",
    "        ```python\n",
    "            schedule = SGDRScheduler(min_lr=1e-5,\n",
    "                                     max_lr=1e-2,\n",
    "                                     steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                                     lr_decay=0.9,\n",
    "                                     cycle_length=5,\n",
    "                                     mult_factor=1.5)\n",
    "            model.fit(X_train, Y_train, epochs=100, callbacks=[schedule])\n",
    "        ```\n",
    "        \n",
    "    # Arguments\n",
    "        min_lr: The lower bound of the learning rate range for the experiment.\n",
    "        max_lr: The upper bound of the learning rate range for the experiment.\n",
    "        steps_per_epoch: Number of mini-batches in the dataset. Calculated as `np.ceil(epoch_size/batch_size)`. \n",
    "        lr_decay: Reduce the max_lr after the completion of each cycle.\n",
    "                  Ex. To reduce the max_lr by 20% after each cycle, set this value to 0.8.\n",
    "        cycle_length: Initial number of epochs in a cycle.\n",
    "        mult_factor: Scale epochs_to_restart after each full cycle completion.\n",
    "        \n",
    "    # References\n",
    "        Blog post: jeremyjordan.me/nn-learning-rate\n",
    "        Original paper: http://arxiv.org/abs/1608.03983\n",
    "    '''\n",
    "    \n",
    "    def __init__(self,\n",
    "                 min_lr,\n",
    "                 max_lr,\n",
    "                 steps_per_epoch,\n",
    "                 lr_decay=1,\n",
    "                 cycle_length=10,\n",
    "                 mult_factor=2):\n",
    "\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.lr_decay = lr_decay\n",
    "\n",
    "        self.batch_since_restart = 0\n",
    "        self.next_restart = cycle_length\n",
    "\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "\n",
    "        self.cycle_length = cycle_length\n",
    "        self.mult_factor = mult_factor\n",
    "\n",
    "        self.history = {}\n",
    "\n",
    "    def clr(self):\n",
    "        '''Calculate the learning rate.'''\n",
    "        fraction_to_restart = self.batch_since_restart / (self.steps_per_epoch * self.cycle_length)\n",
    "        lr = self.min_lr + 0.5 * (self.max_lr - self.min_lr) * (1 + np.cos(fraction_to_restart * np.pi))\n",
    "        return lr\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        '''Initialize the learning rate to the minimum value at the start of training.'''\n",
    "        logs = logs or {}\n",
    "        K.set_value(self.model.optimizer.lr, self.max_lr)\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        '''Record previous batch statistics and update the learning rate.'''\n",
    "        logs = logs or {}\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "\n",
    "        self.batch_since_restart += 1\n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        '''Check for end of current cycle, apply restarts when necessary.'''\n",
    "        if epoch + 1 == self.next_restart:\n",
    "            self.batch_since_restart = 0\n",
    "            self.cycle_length = np.ceil(self.cycle_length * self.mult_factor)\n",
    "            self.next_restart += self.cycle_length\n",
    "            self.max_lr *= self.lr_decay\n",
    "            self.best_weights = self.model.get_weights()\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        '''Set weights to the values from the end of the most recent cycle for best performance.'''\n",
    "        self.model.set_weights(self.best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossHistory(Callback):\n",
    "    def __init__(self):\n",
    "        self.loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def on_batch_end(self, epoch, logs={}):\n",
    "        self.loss.append(logs.get('loss'))\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.val_loss.append(logs.get('val_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SSE custom loss\n",
    "def custom_sse(y_true, y_pred):\n",
    "\n",
    "    # calculating sum of squared difference between target and predicted values \n",
    "    loss = K.sum(K.square(y_pred - y_true))\n",
    "   \n",
    "    # Return a function\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(input_shape, output_shape, neurons, dropout):\n",
    "    x = Input(shape=input_shape)\n",
    "    hidden = LSTM(neurons, return_sequences=True)(x)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    hidden = LSTM(150, return_sequences=True)(x)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    hidden = LSTM(100, return_sequences=True)(x)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    hidden = LSTM(50, return_sequences=False)(hidden)\n",
    "    hidden = Dropout(dropout)(hidden)\n",
    "    y = Dense(output_shape, activation='linear')(hidden)\n",
    "    return Model(inputs=x, outputs=y)\n",
    "\n",
    "model = LSTM_model((input_len, 1), output_len, 200, 0.2)\n",
    "\n",
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "\n",
    "model.compile(optimizer=optimizer, metrics=['mse'], loss = custom_sse)#'mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 2s 7ms/step - loss: 1.0130 - mse: 0.0065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0129528045654297, 0.006490781903266907]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size = 100\n",
    "batch_size = 64\n",
    "\n",
    "# Create the Learning Rate Scheduler Callback\n",
    "schedule = SGDRScheduler(min_lr=1e-5,\n",
    "                         max_lr=1e-4,\n",
    "                         steps_per_epoch=np.ceil(epoch_size/batch_size),\n",
    "                         lr_decay=0.9,\n",
    "                         cycle_length= 3,\n",
    "                         mult_factor=1.5)\n",
    "\n",
    "# Callback function to graph losses\n",
    "lh = LossHistory()\n",
    "\n",
    "# Callback function to stopp when the validation loss stagnates\n",
    "es = EarlyStopping(patience=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5433/5433 [==============================] - 158s 29ms/step - loss: 1.2611 - mse: 0.0039 - val_loss: 0.0177 - val_mse: 5.6296e-05\n",
      "Epoch 2/100\n",
      "5433/5433 [==============================] - 158s 29ms/step - loss: 0.3289 - mse: 0.0010 - val_loss: 0.0092 - val_mse: 2.9676e-05\n",
      "Epoch 3/100\n",
      "5433/5433 [==============================] - 157s 29ms/step - loss: 0.2161 - mse: 6.7533e-04 - val_loss: 0.0058 - val_mse: 1.9064e-05\n",
      "Epoch 4/100\n",
      "5433/5433 [==============================] - 159s 29ms/step - loss: 0.1753 - mse: 5.4773e-04 - val_loss: 0.0168 - val_mse: 5.3222e-05\n",
      "Epoch 5/100\n",
      "5433/5433 [==============================] - 142s 26ms/step - loss: 0.1575 - mse: 4.9207e-04 - val_loss: 0.0052 - val_mse: 1.7049e-05\n",
      "Epoch 6/100\n",
      "5433/5433 [==============================] - 141s 26ms/step - loss: 0.1489 - mse: 4.6544e-04 - val_loss: 0.0047 - val_mse: 1.5415e-05\n",
      "Epoch 7/100\n",
      "5433/5433 [==============================] - 145s 27ms/step - loss: 0.1445 - mse: 4.5145e-04 - val_loss: 0.0111 - val_mse: 3.5439e-05\n",
      "Epoch 8/100\n",
      "5433/5433 [==============================] - 160s 30ms/step - loss: 0.1419 - mse: 4.4350e-04 - val_loss: 0.0152 - val_mse: 4.8602e-05\n",
      "Epoch 9/100\n",
      "5433/5433 [==============================] - 164s 30ms/step - loss: 0.1394 - mse: 4.3558e-04 - val_loss: 0.0056 - val_mse: 1.8319e-05\n",
      "Epoch 10/100\n",
      "5433/5433 [==============================] - 164s 30ms/step - loss: 0.1369 - mse: 4.2778e-04 - val_loss: 0.0069 - val_mse: 2.2354e-05\n",
      "Epoch 11/100\n",
      "5433/5433 [==============================] - 164s 30ms/step - loss: 0.1361 - mse: 4.2529e-04 - val_loss: 0.0058 - val_mse: 1.8905e-05\n",
      "Epoch 12/100\n",
      "5433/5433 [==============================] - 162s 30ms/step - loss: 0.1351 - mse: 4.2229e-04 - val_loss: 0.0145 - val_mse: 4.5864e-05\n",
      "Epoch 13/100\n",
      "5433/5433 [==============================] - 172s 32ms/step - loss: 0.1341 - mse: 4.1905e-04 - val_loss: 0.0113 - val_mse: 3.5839e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f28145ba970>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data = (x_test, y_test),\n",
    "          epochs = epoch_size, batch_size = batch_size, callbacks=[lh, schedule, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"checkpoints/lstm_next_price_win_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"checkpoints/lstm_next_prices_win.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 2s 6ms/step - loss: 0.0077 - mse: 4.8602e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.007693441119045019, 4.860153057961725e-05]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(16,6))\n",
    "ax1.plot(lh.loss)\n",
    "ax1.set_title('Train Loss')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_xlabel('Batch')\n",
    "ax2.plot(lh.val_loss)\n",
    "ax2.set_title('Validation Loss')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_xlabel('Epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on unseen stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation data is: AAPL.\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation data is: {}.\".format(eval_company))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.100266</td>\n",
       "      <td>469033600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.095035</td>\n",
       "      <td>175884800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.088059</td>\n",
       "      <td>105728000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17</th>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.090239</td>\n",
       "      <td>86441600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18</th>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.092855</td>\n",
       "      <td>73449600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>120.500000</td>\n",
       "      <td>121.989998</td>\n",
       "      <td>116.050003</td>\n",
       "      <td>116.320000</td>\n",
       "      <td>116.320000</td>\n",
       "      <td>154515300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10</th>\n",
       "      <td>115.550003</td>\n",
       "      <td>117.589996</td>\n",
       "      <td>114.129997</td>\n",
       "      <td>115.970001</td>\n",
       "      <td>115.970001</td>\n",
       "      <td>138023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-11</th>\n",
       "      <td>117.190002</td>\n",
       "      <td>119.629997</td>\n",
       "      <td>116.440002</td>\n",
       "      <td>119.489998</td>\n",
       "      <td>119.489998</td>\n",
       "      <td>112295000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-12</th>\n",
       "      <td>119.620003</td>\n",
       "      <td>120.529999</td>\n",
       "      <td>118.570000</td>\n",
       "      <td>119.209999</td>\n",
       "      <td>119.209999</td>\n",
       "      <td>103162300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-13</th>\n",
       "      <td>119.440002</td>\n",
       "      <td>119.669998</td>\n",
       "      <td>117.870003</td>\n",
       "      <td>119.260002</td>\n",
       "      <td>119.260002</td>\n",
       "      <td>81581900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10067 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "1980-12-12    0.128348    0.128906    0.128348    0.128348    0.100266   \n",
       "1980-12-15    0.122210    0.122210    0.121652    0.121652    0.095035   \n",
       "1980-12-16    0.113281    0.113281    0.112723    0.112723    0.088059   \n",
       "1980-12-17    0.115513    0.116071    0.115513    0.115513    0.090239   \n",
       "1980-12-18    0.118862    0.119420    0.118862    0.118862    0.092855   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2020-11-09  120.500000  121.989998  116.050003  116.320000  116.320000   \n",
       "2020-11-10  115.550003  117.589996  114.129997  115.970001  115.970001   \n",
       "2020-11-11  117.190002  119.629997  116.440002  119.489998  119.489998   \n",
       "2020-11-12  119.620003  120.529999  118.570000  119.209999  119.209999   \n",
       "2020-11-13  119.440002  119.669998  117.870003  119.260002  119.260002   \n",
       "\n",
       "               Volume  \n",
       "1980-12-12  469033600  \n",
       "1980-12-15  175884800  \n",
       "1980-12-16  105728000  \n",
       "1980-12-17   86441600  \n",
       "1980-12-18   73449600  \n",
       "...               ...  \n",
       "2020-11-09  154515300  \n",
       "2020-11-10  138023400  \n",
       "2020-11-11  112295000  \n",
       "2020-11-12  103162300  \n",
       "2020-11-13   81581900  \n",
       "\n",
       "[10067 rows x 6 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index.name = None\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_stock_price = model.predict(x_test)\n",
    "# Transform the predicted data back to stock prices\n",
    "predicted_stock_price = predicted_stock_price * (total_max - total_min) + total_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fournierp/.local/share/virtualenvs/alfred-Mlefol6Z/lib/python3.8/site-packages/bokeh/io/saving.py:126: UserWarning: save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\n",
      "  warn(\"save() called but no resources were supplied and output_file(...) was never called, defaulting to resources.CDN\")\n",
      "/home/fournierp/.local/share/virtualenvs/alfred-Mlefol6Z/lib/python3.8/site-packages/bokeh/io/saving.py:139: UserWarning: save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\n",
      "  warn(\"save() called but no title was supplied and output_file(...) was never called, using default title 'Bokeh Plot'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/fournierp/Documents/alfred/models/plots/lstm_next_price_win.html'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(test_set, index=df.iloc[:, 3:4].index, columns=[\"Close\"])\n",
    "df1[\"Date\"] = pd.to_datetime(df1.index)\n",
    "dates1 = df1['Date']\n",
    "source1 = ColumnDataSource(data=dict(date=dates1, close=df1['Close']))\n",
    "\n",
    "p = figure(plot_height=300, plot_width=800, tools=\"xpan\", toolbar_location=None,\n",
    "           x_axis_type=\"datetime\", x_axis_location=\"above\",\n",
    "           background_fill_color=\"#efefef\", x_range=(dates1[dates1.index[-100]], dates1[dates1.index[-1]]))\n",
    "tmp = p.x_range # Store it before adding multiple lines\n",
    "p.line('date', 'close', source=source1, legend_label='Real Stock Price', color='green')\n",
    "\n",
    "for i, y_pred in enumerate(predicted_stock_price[::output_len]):\n",
    "    if df1.iloc[input_len+output_len*(i):input_len+output_len*(i+1)].index.shape[0] != output_len:\n",
    "        continue\n",
    "    df2 = pd.DataFrame(y_pred,\n",
    "                       index=df1.iloc[input_len+output_len*(i):input_len+output_len*(i+1)].index,\n",
    "                       columns=[\"Close\"])\n",
    "    df2[\"Date\"] = pd.to_datetime(df2.index)\n",
    "    source2 = ColumnDataSource(data=dict(date=df2['Date'], close=df2['Close']))\n",
    "    p.line('date', 'close', source=source2, legend_label='Predicted Stock Price', color='red')\n",
    "\n",
    "p.yaxis.axis_label = 'Price'\n",
    "\n",
    "hover_tool = HoverTool(\n",
    "    tooltips=[\n",
    "        ( 'date',   '@date{%F}'            ),\n",
    "        ( 'close',  '$@{close}{%0.2f}' ), # use @{ } for field names with spaces\n",
    "    ],\n",
    "\n",
    "    formatters={\n",
    "        '@date'        : 'datetime', # use 'datetime' formatter for '@date' field\n",
    "        '@{close}' : 'printf',   # use 'printf' formatter for '@{adj close}' field\n",
    "                                     # use default 'numeral' formatter for other fields\n",
    "    },\n",
    "\n",
    "    # display a tooltip whenever the cursor is vertically in line with a glyph\n",
    "    # mode='vline'\n",
    ")\n",
    "p.add_tools(hover_tool)\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save\"\n",
    "\n",
    "select = figure(title=\"Drag the middle and edges of the selection box to change the range above\",\n",
    "                plot_height=130, plot_width=800, y_range=p.y_range, tools=TOOLS, \n",
    "                x_axis_type=\"datetime\", y_axis_type=None,\n",
    "                toolbar_location=None, background_fill_color=\"#efefef\")\n",
    "\n",
    "range_tool = RangeTool(x_range=tmp)\n",
    "range_tool.overlay.fill_color = \"navy\"\n",
    "range_tool.overlay.fill_alpha = 0.2\n",
    "\n",
    "select.line('date', 'close', source=source1)\n",
    "select.ygrid.grid_line_color = None\n",
    "select.add_tools(range_tool, hover_tool)\n",
    "select.toolbar.active_multi = range_tool\n",
    "\n",
    "# output_notebook()\n",
    "# show(column(p, select))\n",
    "save(column(p, select), filename=\"plots/lstm_next_price_win.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8175745 , 0.77417564, 0.80022335, 0.84366417, 0.86764336]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_prices = np.reshape(x_test[0], (1, x_test[0].shape[0], 1))\n",
    "\n",
    "predicted_stock_price = model.predict(historical_prices)\n",
    "# Transform the predicted data back to stock prices\n",
    "predicted_stock_price * (total_max - total_min) + total_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12834822],\n",
       "       [0.12165178],\n",
       "       [0.11272322],\n",
       "       [0.11551339],\n",
       "       [0.11886161],\n",
       "       [0.12611607],\n",
       "       [0.13225447],\n",
       "       [0.13783482],\n",
       "       [0.14508928],\n",
       "       [0.15848215],\n",
       "       [0.16071428],\n",
       "       [0.15680803],\n",
       "       [0.15234375],\n",
       "       [0.15401785],\n",
       "       [0.15066965],\n",
       "       [0.14397322],\n",
       "       [0.13783482],\n",
       "       [0.13504465],\n",
       "       [0.1422991 ],\n",
       "       [0.14118303],\n",
       "       [0.13616072],\n",
       "       [0.13671875],\n",
       "       [0.13950893],\n",
       "       [0.13839285],\n",
       "       [0.1467634 ],\n",
       "       [0.1422991 ],\n",
       "       [0.14508928],\n",
       "       [0.1467634 ],\n",
       "       [0.14620535],\n",
       "       [0.14397322]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[0]* (total_max - total_min) + total_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install GPU version of TF\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
